{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c6qBWVbVxn7"
   },
   "source": [
    ">**First and foremost**:  We extract the data from the .csv file and load it in a Panda dataframe in order to use it for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cjE9kk6DxkIo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/content/AmazonData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPntRF3pW3xB"
   },
   "source": [
    "\n",
    ">**Initialization:**\n",
    "We set up the necessary components for the classification:\n",
    "*  Classifiers: We initialize three different classifiers:\n",
    " 1.   Logistic Regression\n",
    " 2.   Support Vector Machine (SVM)\n",
    " 3.   Multi-Layer Perceptron (MLP)\n",
    "*   the KFold method (for distinct train-test splits),\n",
    "*   the TF-IDF method to represent the text descriptions (this technique transforms the text data into a numerical format that captures the importance of each term in relation to the corpus.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d2k8yp94rrjG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "\n",
    "\n",
    "logistic_regression = LogisticRegression(solver='lbfgs')\n",
    "svm_classifier = SVC()\n",
    "mlp_classifier = MLPClassifier(solver='lbfgs',max_iter = 1000)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "vectorizer = sk_text.TfidfVectorizer(min_df=1)\n",
    "df['description'] = df['description'].fillna('')\n",
    "X_tfidf = vectorizer.fit_transform(df['description'])\n",
    "\n",
    "# Dictionaries for organizing the metrics of each model\n",
    "metrics = {\n",
    "    'LogisticRegression': {'confusion_matrices': [],'accuracies': [],'precisions': [],'recalls': [],'f1_scores': []},\n",
    "    'SVC': {'confusion_matrices': [],'accuracies': [],'precisions': [],'recalls': [],'f1_scores': []},\n",
    "    'MLPClassifier': {'confusion_matrices': [],'accuracies': [],'precisions': [],'recalls': [],'f1_scores': []}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4J48UODpYhWf"
   },
   "source": [
    ">**Model Training and Testing**:\n",
    "*   Each classifier was trained on the training data of the respective fold and evaluated on the test data.\n",
    "*   In each fold and for all of the classifiers metrics where calculated and stored in a dictionary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BcpjSmLhrvwz",
    "outputId": "bc53ca20-d92a-405a-8b7a-dc5dc68ab4cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "LogisticRegression 0.8460992907801419\n",
      "SVC 0.8524822695035461\n",
      "MLPClassifier 0.8148936170212766\n",
      "Fold: 2\n",
      "LogisticRegression 0.8460992907801419\n",
      "SVC 0.8560283687943262\n",
      "MLPClassifier 0.8304964539007093\n",
      "Fold: 3\n",
      "LogisticRegression 0.849645390070922\n",
      "SVC 0.8638297872340426\n",
      "MLPClassifier 0.8361702127659575\n",
      "Fold: 4\n",
      "LogisticRegression 0.8489361702127659\n",
      "SVC 0.8602836879432624\n",
      "MLPClassifier 0.8262411347517731\n",
      "Fold: 5\n",
      "LogisticRegression 0.8445706174591909\n",
      "SVC 0.8516678495386799\n",
      "MLPClassifier 0.8076650106458482\n"
     ]
    }
   ],
   "source": [
    "fold_num = 0\n",
    "for train_index, test_index in kf.split(X_tfidf):\n",
    "    fold_num+=1\n",
    "    X_train, X_test =  df['description'][train_index], df['description'][test_index]\n",
    "    y_train, y_test = df['category'][train_index], df['category'][test_index]\n",
    "\n",
    "    vectorizer = sk_text.TfidfVectorizer(min_df=1)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    predictors = [logistic_regression,svm_classifier,mlp_classifier]\n",
    "    print(\"Fold:\",fold_num)\n",
    "    for model in predictors:\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "        model_name = type(model).__name__\n",
    "        print(model_name,model.score(X_test_tfidf,y_test))\n",
    "\n",
    "        # Store metrics for each model\n",
    "        metrics[model_name]['confusion_matrices'].append(confusion_matrix(y_test, predictions))\n",
    "        metrics[model_name]['accuracies'].append(accuracy_score(y_test, predictions))\n",
    "        metrics[model_name]['precisions'].append(precision_score(y_test, predictions, average=None))\n",
    "        metrics[model_name]['recalls'].append(recall_score(y_test, predictions, average=None))\n",
    "        metrics[model_name]['f1_scores'].append(f1_score(y_test, predictions, average=None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRwMCWrBbC9R"
   },
   "source": [
    ">**Performance Metrics:**\n",
    "The average confusion matrix across the five folds was computed, along with the mean values of accuracy, precision, recall, and F1-measure for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3stSjXPiTsqG",
    "outputId": "3bc4dbac-31b4-4a38-85cb-e245882c8b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LogisticRegression:\n",
      "Confusion Matrices: [[753.6  98.6]\n",
      " [117.  440.6]]\n",
      "Accuracies: 0.8470701518606326\n",
      "Precisions: [0.86560504 0.81707219]\n",
      "Recalls: [0.88436425 0.79023685]\n",
      "F1 Scores: [0.87484743 0.80335139]\n",
      "\n",
      "\n",
      "Results for SVC:\n",
      "Confusion Matrices: [[746.6 105.6]\n",
      " [ 96.2 461.4]]\n",
      "Accuracies: 0.8568583926027715\n",
      "Precisions: [0.88583254 0.8136113 ]\n",
      "Recalls: [0.87611652 0.82744518]\n",
      "F1 Scores: [0.88093876 0.8204487 ]\n",
      "\n",
      "\n",
      "Results for MLPClassifier:\n",
      "Confusion Matrices: [[730.6 121.6]\n",
      " [127.8 429.8]]\n",
      "Accuracies: 0.8230932858171128\n",
      "Precisions: [0.851177   0.77910507]\n",
      "Recalls: [0.85734601 0.77043361]\n",
      "F1 Scores: [0.8542492  0.77474224]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_metrics in metrics.items():\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(\"Confusion Matrices:\", np.mean(model_metrics['confusion_matrices'], axis=0))\n",
    "    print(\"Accuracies:\", np.mean(model_metrics['accuracies']))\n",
    "    print(\"Precisions:\", np.mean(model_metrics['precisions'], axis=0))\n",
    "    print(\"Recalls:\", np.mean(model_metrics['recalls'], axis=0))\n",
    "    print(\"F1 Scores:\", np.mean(model_metrics['f1_scores'], axis=0))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcDmEl6sbrUi"
   },
   "source": [
    ">For the **Logistic Regression** classifier in the final fold, we identified the 20 words with the highest positive weights and the 20 words with the lowest negative weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AT1C1MuKYRi_",
    "outputId": "2c19fe70-ccbd-4163-ce99-755ce51de06e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 words with biggest positive weight:\n",
      " ['wall' 'travel' 'battery' 'ac' 'home' '240v' 'desktop' 'qi' 'dock'\n",
      " 'receiver' '60hz' 'original' 'of' '100' 'nokia' 'solar' 'station' 'case'\n",
      " 'is' 'pin']\n",
      "20 words with smallest negative weight:\n",
      " ['car' 'vehicle' 'lighter' '12v' 'cigarette' 'dc' '24v' '12' 'dual'\n",
      " 'indicated' 'auto' 'led' 'retractable' 'road' 'in' 'system' 'powered'\n",
      " 'title' 'cars' 'very']\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression.coef_[0]\n",
    "pos = coefficients.argsort()[-20:][::-1]\n",
    "top_pos = vectorizer.get_feature_names_out()[pos]\n",
    "\n",
    "neg = coefficients.argsort()[:20]\n",
    "top_neg = vectorizer.get_feature_names_out()[neg]\n",
    "\n",
    "print(\"20 words with biggest positive weight:\\n\", top_pos)\n",
    "print(\"20 words with smallest negative weight:\\n\", top_neg)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
